{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50e00161",
   "metadata": {},
   "source": [
    "### Implementing ReAct Agent with Native Function Calling\n",
    "ReAct agent is an AI agent that follows the Reasoning and Acting (ReAct) framework. Modern LLMs increasingly offer native function calling capabilities, which streamline the process of integrating external tools into an agent's workflow. This approach allows the LLM to declare its intent to call a specific function and provide the necessary arguments in a structured format, typically JSON.\n",
    "\n",
    "#### When to Use Native Function Calling\n",
    "\n",
    "Native function calling is generally preferred when:\n",
    "\n",
    "- The chosen LLM explicitly supports this feature (e.g., OpenAI's GPT models, Anthropic's Claude models, Google's Gemini models).\n",
    "- Development speed and reduced parsing complexity are priorities. The LLM handles the formatting of the function call, minimizing the need for custom parsing logic.\n",
    "- The interactions involve complex argument structures that are more easily represented in JSON than in plain text.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58451d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "import inspect\n",
    "import re\n",
    "from tools import web_search, calculator, weather_search, get_current_time\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "SYSTEM_PROMPT_TEMPLATE = \"\"\"\n",
    "You are an expert assistant designed to solve complex tasks by reasoning step-by-step and interacting with available tools.\n",
    "When handling time-related tasks or questions:\n",
    "- If the user explicitly mentions a date, use that date as the reference point\n",
    "- If no date is specified, try to get the current date from your tools\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91af7539",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tool_description(func):\n",
    "  \"\"\"\n",
    "  Generate a tool definition from a function's signature and docstring.\n",
    "\n",
    "  Args:\n",
    "      func: The function to convert to a tool definition\n",
    "\n",
    "  Returns:\n",
    "      A dictionary containing the tool definition for LLM function calling\n",
    "  \"\"\"\n",
    "  # Get function name and docstring\n",
    "  func_name = func.__name__\n",
    "  func_doc = inspect.getdoc(func) or \"\"\n",
    "\n",
    "  # Get function description (first line of docstring)\n",
    "  description = func_doc.split(\n",
    "      '\\n')[0] if func_doc else f\"Call the {func_name} function\"\n",
    "\n",
    "  # Get function signature\n",
    "  signature = inspect.signature(func)\n",
    "  parameters = signature.parameters\n",
    "\n",
    "  # Extract parameter descriptions from docstring using regex\n",
    "  param_desc_pattern = re.compile(\n",
    "      r'\\s*Args:\\s*\\n(.*?)(?:\\n\\s*Returns:|$)', re.DOTALL)\n",
    "  param_match = param_desc_pattern.search(func_doc)\n",
    "\n",
    "  param_descriptions = {}\n",
    "  if param_match:\n",
    "    param_text = param_match.group(1)\n",
    "    # Look for parameter descriptions in format: param_name: description\n",
    "    param_pattern = re.compile(r'\\s*(\\w+):\\s*(.+?)(?=\\n\\s*\\w+:|$)', re.DOTALL)\n",
    "    for match in param_pattern.finditer(param_text):\n",
    "      param_name = match.group(1)\n",
    "      description = match.group(2).strip()\n",
    "      param_descriptions[param_name] = description\n",
    "\n",
    "  # Build parameters object\n",
    "  properties = {}\n",
    "  required = []\n",
    "\n",
    "  for param_name, param in parameters.items():\n",
    "    param_type = \"string\"  # Default to string for simplicity\n",
    "    description = param_descriptions.get(\n",
    "        param_name, f\"The {param_name} parameter\")\n",
    "\n",
    "    properties[param_name] = {\n",
    "        \"type\": param_type,\n",
    "        \"description\": description\n",
    "    }\n",
    "\n",
    "    # If parameter has no default value, mark it as required\n",
    "    if param.default is inspect.Parameter.empty and param_name != 'self':\n",
    "      required.append(param_name)\n",
    "\n",
    "  # Create the tool definition\n",
    "  tool = {\n",
    "      \"type\": \"function\",\n",
    "      \"function\": {\n",
    "          \"name\": func_name,\n",
    "          \"description\": description,\n",
    "          \"parameters\": {\n",
    "              \"type\": \"object\",\n",
    "              \"properties\": properties,\n",
    "              \"required\": required\n",
    "          }\n",
    "      }\n",
    "  }\n",
    "\n",
    "  return tool\n",
    "\n",
    "# Function to generate the available tools description from the available_tools_map\n",
    "\n",
    "\n",
    "def generate_tools_description(tools_map):\n",
    "  \"\"\"Generate a formatted description of available tools from the tools map.\"\"\"\n",
    "  return [generate_tool_description(tool_function) for tool_name, tool_function in tools_map.items()]\n",
    "\n",
    "\n",
    "tools_map = {\n",
    "    \"web_search\": web_search,\n",
    "    \"calculator\": calculator,\n",
    "    \"weather_search\": weather_search,\n",
    "    \"get_current_time\": get_current_time,\n",
    "}\n",
    "\n",
    "\n",
    "def run_react_agent(user_query: str, llm_client, tools_map: dict, max_steps: int = 5):\n",
    "  tools_description = generate_tools_description(tools_map)\n",
    "  messages = []\n",
    "  messages.append({\n",
    "      \"role\": \"system\",\n",
    "      \"content\": SYSTEM_PROMPT_TEMPLATE\n",
    "  })\n",
    "  messages.append({\n",
    "      \"role\": \"user\",\n",
    "      \"content\": user_query\n",
    "  })\n",
    "  print(f\"User: {user_query}\\n\")\n",
    "  for step in range(max_steps):\n",
    "    print(f\"*** Step {step + 1} of {max_steps}: ***\\n\")\n",
    "    try:\n",
    "      response = llm_client.chat.completions.create(\n",
    "          model=os.getenv(\"AZURE_OPENAI_DEPLOYMENT\"),\n",
    "          messages=messages,\n",
    "          tools=tools_description,\n",
    "          tool_choice=\"auto\",\n",
    "      )\n",
    "    except openai.APIError as e:\n",
    "      print(f\"OpenAI API Error: {e}\")\n",
    "      messages.append(\n",
    "          {\"role\": \"assistant\", \"content\": f\"An API error occurred: {e}. Please try again.\"})\n",
    "      break\n",
    "\n",
    "    response_message = response.choices[0].message\n",
    "    tool_calls = response_message.tool_calls\n",
    "\n",
    "    if tool_calls:\n",
    "      messages.append(response_message)  # Add assistant's turn with tool_calls\n",
    "      for tool_call in tool_calls:\n",
    "        function_name = tool_call.function.name\n",
    "        function_args = json.loads(tool_call.function.arguments)\n",
    "\n",
    "        print(f\"LLM wants to call: {function_name} with args: {function_args}\")\n",
    "\n",
    "        if function_name in tools_map:\n",
    "          function_to_call = tools_map[function_name]\n",
    "          try:\n",
    "            function_response = function_to_call(**function_args)\n",
    "            print(f\"Observation (tool output): {function_response}\\n\")\n",
    "            messages.append(\n",
    "                {\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"role\": \"tool\",\n",
    "                    \"name\": function_name,\n",
    "                    \"content\": function_response,\n",
    "                }\n",
    "            )\n",
    "          except Exception as e:\n",
    "            print(f\"Error executing function {function_name}: {e}\\n\")\n",
    "            messages.append(\n",
    "                {\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"role\": \"tool\",\n",
    "                    \"name\": function_name,\n",
    "                    \"content\": f\"Error: {str(e)}\",\n",
    "                }\n",
    "            )\n",
    "        else:\n",
    "          print(f\"Error: Unknown function {function_name}\\n\")\n",
    "          messages.append(\n",
    "              {\n",
    "                  \"tool_call_id\": tool_call.id,\n",
    "                  \"role\": \"tool\",\n",
    "                  \"name\": function_name,\n",
    "                  \"content\": f\"Error: Function {function_name} not found.\",\n",
    "              }\n",
    "          )\n",
    "    else:\n",
    "      # No tool call, LLM provides a direct answer\n",
    "      assistant_response = response_message.content\n",
    "      print(f\"Assistant: {assistant_response}\\n\")\n",
    "      messages.append({\"role\": \"assistant\", \"content\": assistant_response})\n",
    "      if assistant_response:  # Consider it final if there's content and no tool call\n",
    "        return assistant_response  # Task considered complete\n",
    "\n",
    "    if step == max_steps - 1:\n",
    "      print(\"Max steps reached.\")\n",
    "      # Return the last assistant message or a summary\n",
    "      final_content = messages[-1].get(\"content\",\n",
    "                                       \"Could not resolve within max steps.\")\n",
    "      # If last message was a tool response, try to get a summary\n",
    "      if messages[-1][\"role\"] == \"tool\":\n",
    "        try:\n",
    "          summary_response = llm_client.chat.completions.create(\n",
    "              model=os.getenv(\"AZURE_OPENAI_DEPLOYMENT\"),\n",
    "              messages=messages +\n",
    "              [{\"role\": \"user\", \"content\": \"Please summarize the current situation and provide a final answer if possible.\"}],\n",
    "          )\n",
    "          final_content = summary_response.choices.message.content\n",
    "          print(f\"Assistant (summary): {final_content}\\n\")\n",
    "        except openai.APIError as e:\n",
    "          print(f\"OpenAI API Error during summary: {e}\")\n",
    "      return final_content\n",
    "\n",
    "  # Fallback if loop finishes without a clear final answer from LLM without tool_calls\n",
    "  last_assistant_message = next((m[\"content\"] for m in reversed(\n",
    "      messages) if m[\"role\"] == \"assistant\" and m.get(\"content\")), None)\n",
    "  return last_assistant_message if last_assistant_message else \"Agent could not determine a final answer.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f740275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Where was the Microsoft founder was born? And how old is he/she now?\n",
      "\n",
      "*** Step 1 of 10: ***\n",
      "\n",
      "LLM wants to call: web_search with args: {'query': 'Microsoft founder birthplace and birthdate'}\n",
      "LLM wants to call: web_search with args: {'query': 'Microsoft founder birthplace and birthdate'}\n",
      "Observation (tool output): Search failed with status code 202\n",
      "\n",
      "*** Step 2 of 10: ***\n",
      "\n",
      "Observation (tool output): Search failed with status code 202\n",
      "\n",
      "*** Step 2 of 10: ***\n",
      "\n",
      "LLM wants to call: web_search with args: {'query': 'Bill Gates place of birth and age'}\n",
      "LLM wants to call: web_search with args: {'query': 'Bill Gates place of birth and age'}\n",
      "Observation (tool output): Search failed with status code 202\n",
      "\n",
      "*** Step 3 of 10: ***\n",
      "\n",
      "Observation (tool output): Search failed with status code 202\n",
      "\n",
      "*** Step 3 of 10: ***\n",
      "\n",
      "LLM wants to call: web_search with args: {'query': 'Where was Bill Gates born and how old is he'}\n",
      "LLM wants to call: web_search with args: {'query': 'Where was Bill Gates born and how old is he'}\n",
      "Observation (tool output): Search failed with status code 202\n",
      "\n",
      "*** Step 4 of 10: ***\n",
      "\n",
      "Observation (tool output): Search failed with status code 202\n",
      "\n",
      "*** Step 4 of 10: ***\n",
      "\n",
      "LLM wants to call: get_current_time with args: {}\n",
      "Observation (tool output): Current time in UTC: 2025-05-11 09:22:23 UTC\n",
      "\n",
      "*** Step 5 of 10: ***\n",
      "\n",
      "LLM wants to call: get_current_time with args: {}\n",
      "Observation (tool output): Current time in UTC: 2025-05-11 09:22:23 UTC\n",
      "\n",
      "*** Step 5 of 10: ***\n",
      "\n",
      "Assistant: The founder of Microsoft is Bill Gates. He was born in Seattle, Washington, USA.\n",
      "\n",
      "Bill Gates was born on October 28, 1955. As of today (May 11, 2025), he is 69 years old.\n",
      "\n",
      "Final Answer: The founder of Microsoft is Bill Gates. He was born in Seattle, Washington, USA.\n",
      "\n",
      "Bill Gates was born on October 28, 1955. As of today (May 11, 2025), he is 69 years old.\n",
      "Assistant: The founder of Microsoft is Bill Gates. He was born in Seattle, Washington, USA.\n",
      "\n",
      "Bill Gates was born on October 28, 1955. As of today (May 11, 2025), he is 69 years old.\n",
      "\n",
      "Final Answer: The founder of Microsoft is Bill Gates. He was born in Seattle, Washington, USA.\n",
      "\n",
      "Bill Gates was born on October 28, 1955. As of today (May 11, 2025), he is 69 years old.\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# Set up Azure OpenAI client\n",
    "client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    azure_deployment=os.getenv(\"AZURE_OPENAI_DEPLOYMENT\"),\n",
    ")\n",
    "\n",
    "# Update the call to run_custom_react_agent to include available_tools_map\n",
    "final_answer = run_react_agent(\n",
    "    \"Where was the Microsoft founder was born? And how old is he/she now?\",\n",
    "    client,\n",
    "    tools_map,\n",
    "    max_steps=10)\n",
    "print(f\"Final Answer: {final_answer}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
