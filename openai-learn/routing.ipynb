{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb64d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today?\n",
      "\n",
      "\n",
      "\n",
      "¡Hola! ¿En qué puedo ayudarte hoy?\n",
      "\n",
      "\n",
      "\n",
      "Bonjour ! Comment puis-je vous aider aujourd'hui ?\n",
      "\n",
      "\n",
      "\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "from openai.types.responses import ResponseContentPartDoneEvent, ResponseTextDeltaEvent\n",
    "\n",
    "from agents import OpenAIChatCompletionsModel, Agent, RawResponsesStreamEvent, Runner, TResponseInputItem, trace\n",
    "\n",
    "from openai import AsyncAzureOpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = AsyncAzureOpenAI(\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    ")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "This example shows the handoffs/routing pattern. The triage agent receives the first message, and\n",
    "then hands off to the appropriate agent based on the language of the request. Responses are\n",
    "streamed to the user.\n",
    "\"\"\"\n",
    "\n",
    "french_agent = Agent(\n",
    "    name=\"french_agent\",\n",
    "    model=OpenAIChatCompletionsModel(\n",
    "        model=os.getenv(\"AZURE_OPENAI_DEPLOYMENT\"),\n",
    "        openai_client=client,\n",
    "    ),    \n",
    "    instructions=\"You only speak French\",\n",
    ")\n",
    "\n",
    "spanish_agent = Agent(\n",
    "    name=\"spanish_agent\",\n",
    "    model=OpenAIChatCompletionsModel(\n",
    "        model=os.getenv(\"AZURE_OPENAI_DEPLOYMENT\"),\n",
    "        openai_client=client,\n",
    "    ),    \n",
    "    instructions=\"You only speak Spanish\",\n",
    ")\n",
    "\n",
    "english_agent = Agent(\n",
    "    name=\"english_agent\",\n",
    "    model=OpenAIChatCompletionsModel(\n",
    "        model=os.getenv(\"AZURE_OPENAI_DEPLOYMENT\"),\n",
    "        openai_client=client,\n",
    "    ),\n",
    "    instructions=\"You only speak English\",\n",
    ")\n",
    "\n",
    "triage_agent = Agent(\n",
    "    name=\"triage_agent\",\n",
    "    model=OpenAIChatCompletionsModel(\n",
    "        model=os.getenv(\"AZURE_OPENAI_DEPLOYMENT\"),\n",
    "        openai_client=client,\n",
    "    ),\n",
    "    instructions=\"Handoff to the appropriate agent based on the language of the request.\",\n",
    "    handoffs=[french_agent, spanish_agent, english_agent],\n",
    ")\n",
    "\n",
    "\n",
    "async def main():\n",
    "    # We'll create an ID for this conversation, so we can link each trace\n",
    "    conversation_id = str(uuid.uuid4().hex[:16])\n",
    "\n",
    "    msg = input(\"Hi! We speak French, Spanish and English. How can I help? \")\n",
    "    agent = triage_agent\n",
    "    inputs: list[TResponseInputItem] = [{\"content\": msg, \"role\": \"user\"}]\n",
    "\n",
    "    while True:\n",
    "        # Each conversation turn is a single trace. Normally, each input from the user would be an\n",
    "        # API request to your app, and you can wrap the request in a trace()\n",
    "        with trace(\"Routing example\", group_id=conversation_id):\n",
    "            result = Runner.run_streamed(\n",
    "                agent,\n",
    "                input=inputs,\n",
    "            )\n",
    "            async for event in result.stream_events():\n",
    "                if not isinstance(event, RawResponsesStreamEvent):\n",
    "                    continue\n",
    "                data = event.data\n",
    "                if isinstance(data, ResponseTextDeltaEvent):\n",
    "                    print(data.delta, end=\"\", flush=True)\n",
    "                elif isinstance(data, ResponseContentPartDoneEvent):\n",
    "                    print(\"\\n\")\n",
    "\n",
    "        inputs = result.to_input_list()\n",
    "        print(\"\\n\")\n",
    "\n",
    "        user_msg = input(\"Enter a message: \")\n",
    "\n",
    "        if user_msg.lower() in [\"quit\", \"exit\"]:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "                    \n",
    "        inputs.append({\"content\": user_msg, \"role\": \"user\"})\n",
    "        # agent = result.current_agent\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    await main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
